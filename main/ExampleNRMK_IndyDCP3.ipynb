{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0baaf954",
   "metadata": {},
   "source": [
    "http://docs.neuromeka.com/3.2.0/kr/IndyAPI/indydcp3_python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9407f033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.utils import *\n",
    "from src.core.pybullet_core import PybulletCore\n",
    "\n",
    "from neuromeka import IndyDCP3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df204d9",
   "metadata": {},
   "source": [
    "# Connect to Indy7\n",
    "***\n",
    "- **Robot #1**: 192.168.0.8\n",
    "- **Robot #2**: 192.168.0.11\n",
    "- **Robot #3**: 192.168.0.12\n",
    "- **Robot #4**: 192.168.0.13\n",
    "- **Robot #5**: 192.168.0.10\n",
    "- **Robot #6**: 192.168.0.9\n",
    "***\n",
    "<img src=\"./figures/indy7v2_image.jpg\" width=\"20%\" height=\"20%\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c82186c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indy = IndyDCP3(robot_ip='192.168.0.12', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d6528",
   "metadata": {},
   "source": [
    "# Real-time Data Acquisition Functions\n",
    "http://docs.neuromeka.com/3.2.0/kr/IndyAPI/indydcp3_python/#_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae65e0",
   "metadata": {},
   "source": [
    "### get_motion_data()\n",
    ": Information on Motion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d193bdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mspeed_ratio: \u001b[30m\u001b[0m100\n",
      "\u001b[1m\u001b[30mtraj_state: \u001b[30m\u001b[0m0\n",
      "\u001b[1m\u001b[30mtraj_progress: \u001b[30m\u001b[0m0\n",
      "\u001b[1m\u001b[30mis_in_motion: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mis_target_reached: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mis_pausing: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mis_stopping: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mhas_motion: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mmotion_id: \u001b[30m\u001b[0m0\n",
      "\u001b[1m\u001b[30mremain_distance: \u001b[30m\u001b[0m0.0\n",
      "\u001b[1m\u001b[30mmotion_queue_size: \u001b[30m\u001b[0m0\n",
      "\u001b[1m\u001b[30mcur_traj_progress: \u001b[30m\u001b[0m0\n"
     ]
    }
   ],
   "source": [
    "motion_data = indy.get_motion_data()\n",
    "for key, value in zip(motion_data.keys(), motion_data.values()):\n",
    "    PRINT_BLACK(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68c34e",
   "metadata": {},
   "source": [
    "### get_control_data()\n",
    ": Information on Control Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data = indy.get_control_data()\n",
    "for key, value in zip(control_data.keys(), control_data.values()):\n",
    "    PRINT_BLACK(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf52bd9",
   "metadata": {},
   "source": [
    "### get_violation_data()\n",
    ": Information on Violation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_data = indy.get_violation_data()\n",
    "for key, value in zip(violation_data.keys(), violation_data.values()):\n",
    "    PRINT_BLACK(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0eb40",
   "metadata": {},
   "source": [
    "# Motion Command Data Related Functions\n",
    "http://docs.neuromeka.com/3.2.0/kr/IndyAPI/indydcp3_python/#_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7668f",
   "metadata": {},
   "source": [
    "### stop_motion(stop_category)\n",
    ": Stops motion in the specified manner (IMMEDIATE_BRAKE, SMOOTH_BRAKE, SMOOTH_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMMEDIATE_BRAKE = 0 # cat0 stop\n",
    "SMOOTH_BRAKE = 1    # cat1 stop\n",
    "SMOOTH_ONLY = 2     # cat2 stop\n",
    "stop_response = indy.stop_motion(stop_category=SMOOTH_ONLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fce56",
   "metadata": {},
   "source": [
    "### movej(...)\n",
    ": Moves the robot to the specified joint target position with various conditions.\n",
    "***\n",
    "### Arguments\n",
    "- **jtarget**         : List value in degrees (ex. **jtarget**=[0, -22, 100, 0, 100, 0])\n",
    "- **blending_type**   : Motion blending types (0: no blending, 1: override blending, 2: duplicate blending)\n",
    "- **base_type**       : reference joint frame types (0: alsolute joint values, 1: relative joint values)\n",
    "- **blending_radius** : blending radius betweem each via-points\n",
    "- **vel_ratio**       : motion velocity level (0~100)\n",
    "- **acc_ratio**       : motion acceleration level (0~900)\n",
    "\n",
    "### [Asynchronized motion blending] Overrive vs Duplicate\n",
    "<img src=\"./figures/asynchronized.png\" width=\"45%\" height=\"45%\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea1c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': '0', 'msg': ''}\n",
      "\u001b[1m\u001b[34m*** Robot's motion info ***\u001b[30m\u001b[0m\n",
      "\u001b[1m\u001b[30mis_in_motion: \u001b[30m\u001b[0mTrue\n",
      "\u001b[1m\u001b[30mis_target_reached: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mhas_motion: \u001b[30m\u001b[0mTrue\n",
      "\n",
      "\u001b[1m\u001b[34m*** Robot's motion info ***\u001b[30m\u001b[0m\n",
      "\u001b[1m\u001b[30mis_in_motion: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mis_target_reached: \u001b[30m\u001b[0mTrue\n",
      "\u001b[1m\u001b[30mhas_motion: \u001b[30m\u001b[0mFalse\n",
      "\n",
      "{'code': '0', 'msg': ''}\n",
      "\u001b[1m\u001b[34m*** Robot's motion info ***\u001b[30m\u001b[0m\n",
      "\u001b[1m\u001b[30mis_in_motion: \u001b[30m\u001b[0mTrue\n",
      "\u001b[1m\u001b[30mis_target_reached: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mhas_motion: \u001b[30m\u001b[0mTrue\n",
      "\n",
      "\u001b[1m\u001b[34m*** Robot's motion info ***\u001b[30m\u001b[0m\n",
      "\u001b[1m\u001b[30mis_in_motion: \u001b[30m\u001b[0mFalse\n",
      "\u001b[1m\u001b[30mis_target_reached: \u001b[30m\u001b[0mTrue\n",
      "\u001b[1m\u001b[30mhas_motion: \u001b[30m\u001b[0mFalse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Joint motion 1\n",
    "target_pos = [0, -15, -75, 0, 0, -10]\n",
    "move_response = indy.movej(jtarget=target_pos)\n",
    "print(move_response)\n",
    "\n",
    "PRINT_BLUE(\"*** Robot's motion info ***\")\n",
    "motion_data = indy.get_motion_data()\n",
    "PRINT_BLACK(\"is_in_motion\", motion_data[\"is_in_motion\"])\n",
    "PRINT_BLACK(\"is_target_reached\", motion_data[\"is_target_reached\"])\n",
    "PRINT_BLACK(\"has_motion\", motion_data[\"has_motion\"])\n",
    "print()\n",
    "\n",
    "time.sleep(7)\n",
    "\n",
    "PRINT_BLUE(\"*** Robot's motion info ***\")\n",
    "motion_data = indy.get_motion_data()\n",
    "PRINT_BLACK(\"is_in_motion\", motion_data[\"is_in_motion\"])\n",
    "PRINT_BLACK(\"is_target_reached\", motion_data[\"is_target_reached\"])\n",
    "PRINT_BLACK(\"has_motion\", motion_data[\"has_motion\"])\n",
    "print()\n",
    "    \n",
    "### Joint motion 2\n",
    "target_pos = [0,-15, -75, -25, 0, -10]\n",
    "move_response = indy.movej(jtarget=target_pos)\n",
    "print(move_response)\n",
    "\n",
    "PRINT_BLUE(\"*** Robot's motion info ***\")\n",
    "motion_data = indy.get_motion_data()\n",
    "PRINT_BLACK(\"is_in_motion\", motion_data[\"is_in_motion\"])\n",
    "PRINT_BLACK(\"is_target_reached\", motion_data[\"is_target_reached\"])\n",
    "PRINT_BLACK(\"has_motion\", motion_data[\"has_motion\"])\n",
    "print()\n",
    "\n",
    "time.sleep(7)\n",
    "\n",
    "PRINT_BLUE(\"*** Robot's motion info ***\")\n",
    "motion_data = indy.get_motion_data()\n",
    "PRINT_BLACK(\"is_in_motion\", motion_data[\"is_in_motion\"])\n",
    "PRINT_BLACK(\"is_target_reached\", motion_data[\"is_target_reached\"])\n",
    "PRINT_BLACK(\"has_motion\", motion_data[\"has_motion\"])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2aea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_BLENDING = 0\n",
    "OVERRIDE_BLENDING = 1\n",
    "DUPLICATE_BLENDING = 2\n",
    "\n",
    "target_pos1 = [50, -22, 100, 0, 100, 0]\n",
    "target_pos2 = [0, -22, 100, 0, 100, 0]\n",
    "\n",
    "indy.movej(target_pos1, blending_type=OVERRIDE_BLENDING)\n",
    "time.sleep(0.5)\n",
    "indy.movej(target_pos2, blending_type=OVERRIDE_BLENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96901b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSOLUTE_JOINT = 0\n",
    "RELATIVE_JOINT = 1\n",
    "\n",
    "target_pos1 = [-30, 0, 0, 0, 0, 0]\n",
    "\n",
    "# move_response = indy.movej(target_pos1, blending_type=NO_BLENDING, base_type=ABSOLUTE_JOINT, vel_ratio=50, acc_ratio=100)\n",
    "move_response = indy.movej(target_pos1, blending_type=NO_BLENDING, base_type=RELATIVE_JOINT, vel_ratio=50, acc_ratio=100)\n",
    "print(move_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b36588",
   "metadata": {},
   "source": [
    "# movej_time(...)\n",
    ": Moves the robot to the joint target position over a specified time.\n",
    "***\n",
    "### Arguments\n",
    "- **jtarget**         : List value in degrees (ex. **jtarget**=[0, -22, 100, 0, 100, 0])\n",
    "- **blending_type**   : Motion blending types (0: no blending, 1: override blending, 2: duplicate blending)\n",
    "- **base_type**       : reference joint frame types (0: alsolute joint values, 1: relative joint values)\n",
    "- **blending_radius** : blending radius betweem each via-points\n",
    "- **move_time**       : entire movement time (sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d0c1f",
   "metadata": {},
   "source": [
    "# movel(...), movel_time(...)\n",
    ": Moves the robot linearly to the specified task target position with various conditions.\n",
    "***\n",
    "### Arguments\n",
    "- **ttarget**         : List value in [xyz(mm), eul_xyz(deg)] (ex. **ttarget**=[0.4, 0, 0.4, 0, 180, 0])\n",
    "- **blending_type**   : Motion blending types (0: no blending, 1: override blending, 2: duplicate blending)\n",
    "- **base_type**       : reference task frame types (0: alsolute world frame, 1: relative world frame, 2: relative TCP frame)\n",
    "- **blending_radius** : blending radius betweem each via-points\n",
    "- (movel) **vel_ratio**       : motion velocity level (0~100)\n",
    "- (movel) **acc_ratio**       : motion acceleration level (0~900)\n",
    "- (movel_time) **move_time**       : entire movement time (sec)\n",
    "***\n",
    "<img src=\"./figures/BaseFrame.png\" width=\"90%\" height=\"90%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5dd55",
   "metadata": {},
   "source": [
    "# Inverse Kinematics & Direct Teaching Mode\n",
    "***\n",
    "http://docs.neuromeka.com/3.2.0/en/IndyAPI/indydcp3_python/#inverse-kinematics-and-simulation-mode-related-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc46a4",
   "metadata": {},
   "source": [
    "### inverse_kin(tpos, init_jpos)\n",
    ": A function that calculates the joint positions that can reach a given task space coordinate, based on the initial joint positions.\n",
    "***\n",
    "### Arguments\n",
    "- **tpos**         : Target task space position (ex. **tpos**=[0.4, 0, 0.4, 0, 180, 0])\n",
    "- **init_jpos**   : Initial joint position\n",
    "***\n",
    "### Return\n",
    "- **jpos**         : List of calculated joint positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040c4ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tpos [569.076, -202.4991, 734.29706, 89.76016, 99.995255, 89.76389]\n",
      "Current jpos [9.07961e-05, -15.014089, -75.02631, 0.005438776, -0.001142143, -10.00055]\n",
      "\u001b[1m\u001b[30mjpos: \u001b[30m\u001b[0m[9.07961e-05, -15.014089, -75.02631, 0.005438776, -0.001142143, -10.00055]\n",
      "\u001b[1m\u001b[30mresponse: \u001b[30m\u001b[0m{'msg': 'InverseKinematics Success', 'code': '0'}\n"
     ]
    }
   ],
   "source": [
    "tpos = indy.get_control_data()['p']\n",
    "init_jpos = indy.get_control_data()['q']\n",
    "\n",
    "print(\"Current tpos\", tpos)\n",
    "print(\"Current jpos\", init_jpos)\n",
    "\n",
    "ik_data = indy.inverse_kin(tpos, init_jpos)\n",
    "PRINT_BLACK(\"jpos\", ik_data[\"jpos\"])\n",
    "PRINT_BLACK(\"response\", ik_data[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794abee9",
   "metadata": {},
   "source": [
    "### set_direct_teaching(enable)\n",
    ": Switching to the direct teaching mode.\n",
    "***\n",
    "### Arguments\n",
    "- **enable**         : Enable/Disable direct teaching mode via True/False (Bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a120276",
   "metadata": {},
   "outputs": [],
   "source": [
    "indy.set_direct_teaching(enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "indy.set_direct_teaching(enable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indy.set_friction_comp(\n",
    "    control_comp=False, \n",
    "    control_comp_levels=[5, 5, 5, 5, 5, 5],\n",
    "    dt_comp=True,\n",
    "    dt_comp_levels=[2, 5, 2, 2, 5, 5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indy.set_direct_teaching(enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indy.set_direct_teaching(enable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130129e4",
   "metadata": {},
   "source": [
    "### recover()\n",
    ": A function to recover the robot from error or collision situations. When the robot falls into an abnormal state, calling this function can restore it to normal condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7653deef-9f1d-4a33-bb4c-0bc933001a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': 'Success', 'code': '0'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indy.recover()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967ceb83",
   "metadata": {},
   "source": [
    "# Future works \n",
    "### (TODO... Out of the scope of this course! (For an Advanced Robotics))\n",
    "- Customized low-level torque controller using IndySDK3.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
